<?php

declare(strict_types=1);

namespace Tests\Providers\VertexAI;

use Illuminate\Http\Client\Request;
use Illuminate\Support\Facades\Http;
use Prism\Prism\Enums\FinishReason;
use Prism\Prism\Enums\Provider;
use Prism\Prism\Facades\Prism;
use Prism\Prism\Tool;
use Prism\Prism\ValueObjects\Messages\AssistantMessage;
use Prism\Prism\ValueObjects\Messages\ToolResultMessage;
use Prism\Prism\ValueObjects\Messages\UserMessage;
use Tests\Fixtures\FixtureResponse;

beforeEach(function (): void {
    config()->set('prism.providers.vertexai.project_id', 'test-project');
    config()->set('prism.providers.vertexai.location', 'us-central1');
    config()->set('prism.providers.vertexai.api_key', 'test-key-1234');
});

describe('Text generation for Vertex AI', function (): void {
    it('can generate text with a prompt', function (): void {
        FixtureResponse::fakeResponseSequence('*', 'vertexai/generate-text-with-a-prompt');

        $response = Prism::text()
            ->using(Provider::VertexAI, 'gemini-2.5-flash')
            ->withPrompt('Who are you?')
            ->withMaxTokens(10)
            ->asText();

        expect($response->text)->toBe(
            "I am a large language model, trained by Google.  I am an AI, and I don't have a name, feelings, or personal experiences.  My purpose is to process information and respond to a wide range of prompts and questions in a helpful and informative way.\n"
        )
            ->and($response->usage->promptTokens)->toBe(4)
            ->and($response->usage->completionTokens)->toBe(57)
            ->and($response->meta->id)->toBe('')
            ->and($response->meta->model)->toBe('gemini-2.5-flash')
            ->and($response->finishReason)->toBe(FinishReason::Stop);
    });

    it('can generate text with a system prompt', function (): void {
        FixtureResponse::fakeResponseSequence('*', 'vertexai/generate-text-with-system-prompt');

        $response = Prism::text()
            ->using(Provider::VertexAI, 'gemini-2.5-flash')
            ->withSystemPrompt('You are a helpful AI assistant named Prism generated by echolabs')
            ->withPrompt('Who are you?')
            ->asText();

        expect($response->text)->toBe('I am Prism, a helpful AI assistant created by echo labs.')
            ->and($response->usage->promptTokens)->toBe(17)
            ->and($response->usage->completionTokens)->toBe(14)
            ->and($response->meta->id)->toBe('')
            ->and($response->meta->model)->toBe('gemini-2.5-flash')
            ->and($response->finishReason)->toBe(FinishReason::Stop);
    });

    it('can generate text using multiple tools and multiple steps', function (): void {
        FixtureResponse::fakeResponseSequence('*', 'vertexai/generate-text-with-multiple-tools');

        $tools = [
            (new Tool)
                ->as('get_weather')
                ->for('use this tool when you need to get weather for the city')
                ->withStringParameter('city', 'The city that you want the weather for')
                ->using(fn (string $city): string => 'The weather will be 45Â° and cold'),
            (new Tool)
                ->as('search_games')
                ->for('useful for searching current games times in the city')
                ->withStringParameter('city', 'The city that you want the game times for')
                ->using(fn (string $city): string => 'The tigers game is at 3pm in detroit'),
        ];

        $response = Prism::text()
            ->using(Provider::VertexAI, 'gemini-2.5-flash')
            ->withTools($tools)
            ->withMaxSteps(5)
            ->withPrompt('What time is the tigers game today in Detroit and should I wear a coat? please check all the details from tools')
            ->asText();

        // Assert tool calls in the first step
        $firstStep = $response->steps[0];
        expect($firstStep->toolCalls)->toHaveCount(2);
        expect($firstStep->toolCalls[0]->name)->toBe('search_games');
        expect($firstStep->toolCalls[0]->arguments())->toBe([
            'city' => 'Detroit',
        ]);
        expect($firstStep->toolCalls[1]->name)->toBe('get_weather');
        expect($firstStep->toolCalls[1]->arguments())->toBe([
            'city' => 'Detroit',
        ]);

        // Verify the assistant message from step 1 is present in step 2's input messages
        $secondStep = $response->steps[1];
        expect($secondStep->messages)->toHaveCount(3);
        expect($secondStep->messages[0])->toBeInstanceOf(UserMessage::class);
        expect($secondStep->messages[1])->toBeInstanceOf(AssistantMessage::class);
        expect($secondStep->messages[1]->toolCalls)->toHaveCount(2);
        expect($secondStep->messages[1]->toolCalls[0]->name)->toBe('search_games');
        expect($secondStep->messages[1]->toolCalls[1]->name)->toBe('get_weather');
        expect($secondStep->messages[2])->toBeInstanceOf(ToolResultMessage::class);

        // Assert usage (combined from both responses)
        expect($response->usage->promptTokens)->toBe(350)
            ->and($response->usage->completionTokens)->toBe(42);

        // Assert response
        expect($response->meta->id)->toBe('')
            ->and($response->meta->model)->toBe('gemini-2.5-flash')
            ->and($response->text)->toBe('The tigers game is at 3pm today in Detroit.  The weather will be 45Â° and cold, so you should wear a coat.');
    });

    it('sends requests to the correct Vertex AI URL', function (): void {
        FixtureResponse::fakeResponseSequence('*', 'vertexai/generate-text-with-a-prompt');

        Prism::text()
            ->using(Provider::VertexAI, 'gemini-2.5-flash')
            ->withPrompt('Who are you?')
            ->asText();

        Http::assertSent(function (Request $request): bool {
            $url = $request->url();

            expect($url)->toContain('aiplatform.googleapis.com')
                ->and($url)->toContain('projects/test-project')
                ->and($url)->toContain('locations/us-central1')
                ->and($url)->toContain('publishers/google/models')
                ->and($url)->toContain('gemini-2.5-flash:generateContent');

            return true;
        });
    });

    it('includes API key as query parameter', function (): void {
        FixtureResponse::fakeResponseSequence('*', 'vertexai/generate-text-with-a-prompt');

        Prism::text()
            ->using(Provider::VertexAI, 'gemini-2.5-flash')
            ->withPrompt('Who are you?')
            ->asText();

        Http::assertSent(function (Request $request): bool {
            $url = $request->url();

            expect($url)->toContain('key=test-key-1234');

            return true;
        });
    });
});
